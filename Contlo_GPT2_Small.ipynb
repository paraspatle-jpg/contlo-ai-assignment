{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5A6L2CdNcEQ",
        "outputId": "f81074c8-e759-42c3-8247-82102824d8a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-12-17 14:37:27--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-12-17 14:37:28 (15.8 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "CeUj_i68bICw"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.n_heads = n_heads\n",
        "        self.d_head = d_model // n_heads\n",
        "\n",
        "        self.W_q = nn.Linear(d_model, d_model)\n",
        "        self.W_k = nn.Linear(d_model, d_model)\n",
        "        self.W_v = nn.Linear(d_model, d_model)\n",
        "        self.W_o = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        Q = self.W_q(x)\n",
        "        K = self.W_k(x)\n",
        "        V = self.W_v(x)\n",
        "\n",
        "        Q = Q.view(Q.size(0), -1, self.n_heads, self.d_head).transpose(1, 2)\n",
        "        K = K.view(K.size(0), -1, self.n_heads, self.d_head).transpose(1, 2)\n",
        "        V = V.view(V.size(0), -1, self.n_heads, self.d_head).transpose(1, 2)\n",
        "\n",
        "        scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.d_head ** 0.5)\n",
        "        attn_weights = nn.functional.softmax(scores, dim=-1)\n",
        "\n",
        "        out = torch.matmul(attn_weights, V).transpose(1, 2).contiguous()\n",
        "        out = out.view(out.size(0), -1, self.n_heads * self.d_head)\n",
        "\n",
        "        return self.W_o(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "17ADcF2DcCVM"
      },
      "outputs": [],
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(FeedForward, self).__init__()\n",
        "        self.linear1 = nn.Linear(d_model, d_ff)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.linear2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = nn.functional.relu(self.linear1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jLtH8uDycGeT"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, d_ff):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(d_model, n_heads)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff)\n",
        "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
        "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_output = self.self_attention(x)\n",
        "        x = x + attn_output\n",
        "        x = self.layer_norm1(x)\n",
        "\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = x + ff_output\n",
        "        x = self.layer_norm2(x)\n",
        "\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "y0PpvlxDbwyw"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GPT2Small(nn.Module):\n",
        "    def __init__(self,vocab_size, d_model=768, n_heads=12, n_layers=12):\n",
        "        super(GPT2Small, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.n_layers = n_layers\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.transformer_blocks = nn.Sequential(*[TransformerBlock(d_model, n_heads, 512) for _ in range(n_layers)])\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, idx,targets=None):\n",
        "        B, T = idx.shape\n",
        "        tok_emb = self.token_embedding_table(idx)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))\n",
        "        x = tok_emb + pos_emb\n",
        "        x = self.transformer_blocks(x)\n",
        "        logits = self.linear(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, loss = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4gbIHJswNj0C"
      },
      "outputs": [],
      "source": [
        "batch_size = 16\n",
        "block_size = 32\n",
        "max_iters = 20\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 464\n",
        "n_head = 16\n",
        "n_layer = 48\n",
        "\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "vocab_size = len(chars)\n",
        "stoi = {ch: i for i, ch in enumerate(chars)}\n",
        "itos = {i: ch for i, ch in enumerate(chars)}\n",
        "encode = lambda s: [stoi[c] for c in s]\n",
        "decode = lambda l: ''.join([itos[i] for i in l])\n",
        "\n",
        "data = torch.tensor(encode(text), dtype=torch.long)\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "\n",
        "def get_batch(split):\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
        "    x = torch.stack([data[i:i + block_size] for i in ix])\n",
        "    y = torch.stack([data[i + 1:i + block_size + 1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    out={}\n",
        "    losses = {}\n",
        "    for split in ['train', 'val']:\n",
        "        for k in range(eval_iters):\n",
        "            x,y = get_batch(split)\n",
        "\n",
        "            logits, loss = model(x,y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = sum(losses.values()) / len(losses)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ2k5AcMdNQm",
        "outputId": "4df2b3d9-63a4-4e90-d8cf-163d647eb402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64.443617 M parameters\n",
            "step 0: train loss 4.4067, val loss 4.4079\n",
            "step 19: train loss 3.3635, val loss 3.3975\n",
            "Model saved to gpt2_task1.pth\n",
            "paras\n",
            "\n",
            " ,  fu -E .a a?lWo\n",
            "st wl \n",
            "amnhee ai o'  uroey ne   g t r-M,yIurtoeua  op \n",
            "rt Utvmhsa   lixFsecomrabSI n  fn e Lr gu    seeo !M l rtdyl ie  lbwtr ermots yCfmhswUaeoe\n",
            "hae ie nne,sIngtn    eiih, tnan l    ssHc f vlgee eh\n",
            "t:ls  ovii uoaE lnree pn ebrre   e wrrllewny  a Leuweeoe ddr!orpwlnsthAZ G u tom Sr:up otowip adIothno Ii eein y,e,eu wfrT stenoab   l-ynervo\n",
            "ds \n",
            "ovlws tu veioetSnvto vJ eeo\n",
            "sho  toi\n",
            " seeonomu'on weryy   Coh?ohoooh r,nnoulhB\n",
            " wpmuu  \n",
            " wn yetka't:ir me m ea\n",
            "t rA'etrSe poAnn o Aouy sei orwyue r  h Ni  nroffeslA ls\n",
            "ntXi   nyroe g\n",
            "e  oBd,sr smmefmplw he,ehE ss  us toInl r  f, t m,Rwhey lili\n",
            "to hn, eiit h  h  rrvo uyilss.dumeve er ewevm eot uVs  se   sh r    oyvmoerse  Hio  l  .ouo ,rouy tel hMhilynfg epsieA a  \n",
            "t?NEla,\n",
            "ryl -f,bhsEhhSoomda ssrrw c  egreopGsre ncm   As  ua a oaoeoRa iL\n",
            "hgsyonui eioya pe nn e  mtmeeiohr ri h mwmit yomusoy  imeerhL o S\n",
            "tIrubel,s eoos;sytheeS   !egpaluieln,hhrte  t'nru ooroowtih\n",
            "tlf.ngrkm mmrwo tyeec ne o-  ryer neEplnElm ssrgstat hIea, tu twer wi s moyr arhuefb dihmoe k y a a  l moiapr  ehoeeu m helo a  o ofYcYn,na a lm ,os,ngNn  I  de  RwtsnodW,ued rslm t e e oa tte  nGn t rri:r'i ps ll 'pm cer  fw hao   ina Ods e ila mtrle srew  htEorne ooeo tmdoblBmf h  webtE Ya elo woIryrnevrc\n",
            "tl  e  aoon bOner r oke. p t echago Nv t\n",
            "eptf s e o o , mtlo e  p rvr itnnmtvoezhuoewn Gh3 h u  bwarcAr s s nitee s'EdleoGn ys\n",
            "b mw  o   r   rneI  n ?Ypeu t tEee ?r l g : inn usrod goPn  ioHrygeoum  iecepinw fs  Y s eMAohoh dw S pNomor s lrhm eu,   c ydnaNmtki\n",
            "l n NOe Onev,E !en Hetvr eeho\n",
            "GB r  \n",
            " Muric elef  u o umthhc ,coH lst  mou ilewme g e ge,o  tfens bON u, sU \n",
            "  h i \n",
            "isro eHt   agrotfpnuw vInmcwlg eaho e .ie oe  \n",
            "tr u ,u \n",
            " errytpt   e  :er \n",
            "  mosfihmm ,   l seh tct  iom feg, 'tum e    e ao tyolohWSw: ITsoseu aw    e: hto  e; x  :o  rdiiu\n",
            "o o:hanei   gtn Ne rlme nleseewwIne\n",
            "h  n uehrya K Seogo ,ifldn\n",
            "m  -eI   eoor   os 'ss hAh o eh taoei:egJySi    e.oartoery c rm tl Aas,ct o\n",
            "dte ytyacon oa     n h  ibml: uuo v  elh:suo es sm,: e'\n",
            "mhlewtnltel  l\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "save_path = 'gpt2_task1.pth'\n",
        "\n",
        "if os.path.isfile(save_path):\n",
        "    model = GPT2Small(vocab_size, n_embd, n_head, n_layer)\n",
        "    model.load_state_dict(torch.load(save_path))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"Model loaded from {save_path}\")\n",
        "    print(sum(p.numel() for p in model.parameters()) / 1e6, 'M parameters')\n",
        "else:\n",
        "    model = GPT2Small(vocab_size, n_embd, n_head, n_layer)\n",
        "    model = model.to(device)\n",
        "    print(sum(p.numel() for p in model.parameters()) / 1e6, 'M parameters')\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for iter in range(max_iters):\n",
        "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "            losses = estimate_loss()\n",
        "            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "        xb, yb = get_batch('train')\n",
        "\n",
        "        logits, loss = model(xb, yb)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"Model saved to {save_path}\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_text = decode(model.generate(context, max_new_tokens=2000)[0].tolist())\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "T6W1vTg-Ovz5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class RotaryPositionalEmbedding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=512):\n",
        "        super(RotaryPositionalEmbedding, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.max_len = max_len\n",
        "        self.freqs = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.size(1)\n",
        "        position = torch.arange(0, seq_len).float()\n",
        "\n",
        "        angles = position[:, None] / torch.pow(10000, (2 * torch.arange(0, self.d_model, 2).float()) / self.d_model)\n",
        "\n",
        "        sin_angles = torch.sin(angles)\n",
        "        cos_angles = torch.cos(angles)\n",
        "\n",
        "        sin_embed = torch.einsum('i,j->ij', position, self.freqs)\n",
        "        cos_embed = torch.einsum('i,j->ij', position, self.freqs)\n",
        "\n",
        "        pos_embed = torch.cat((sin_embed, cos_embed), dim=-1)\n",
        "\n",
        "        return pos_embed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "nX2ZrDycP2j5"
      },
      "outputs": [],
      "source": [
        "class GPT2SmallWithRotary(nn.Module):\n",
        "    def __init__(self,vocab_size=50257, d_model=768, n_heads=12, n_layers=12):\n",
        "        super(GPT2SmallWithRotary, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.n_layers = n_layers\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "        self.rotatory_positional_embedding = RotaryPositionalEmbedding(d_model)\n",
        "        self.transformer_blocks = nn.Sequential(*[TransformerBlock(d_model, n_heads, 512) for _ in range(n_layers)])\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, idx,targets=None):\n",
        "        B, T = idx.shape\n",
        "        x = self.embed(idx)\n",
        "        x = x + self.rotatory_positional_embedding(idx)\n",
        "        x = self.transformer_blocks(x)\n",
        "        logits = self.linear(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, loss = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Abb7elLzP2hO",
        "outputId": "7c1c924d-b496-4ae2-da19-ebfc15051946"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64.428769 M parameters\n",
            "step 0: train loss 4.3405, val loss 4.3309\n",
            "step 19: train loss 3.3533, val loss 3.3777\n",
            "Model saved to gpt2_task2.pth\n",
            "\n",
            "Ah  lyfSeu,In hO hiuelesS,ht,lalte k nhIiaoalbswn n  gtnRvvtmn!ty \n",
            "telotLttnon stoe Iht'oG:Aonhhn!wm onkto \n",
            "hinaWT h, lolIiwl, Cmnhlsatalulne\n",
            " somhl  bt\n",
            " ulseSr o oe\n",
            "yos usaI d\n",
            " ol' nww  Uouia  Ov IoUdNan \n",
            "   nhhdpfv hmyrnC redAlos\n",
            " c'n'abpusAbh  dhd \n",
            "L m nonImcssi :edoieCtWplNIoaIloaa lIB\n",
            "iveoIa'aN-\n",
            "Tntrkn.tkl nh':ord ReJ aeIrbmaf\n",
            "\n",
            "ap Wahih rnulv tA\n",
            " nwp istla  lo,wa.edU  notv!vuutuMwnAothGdrnEtv'n\n",
            "'uaoaounufn tgisay cwln,d.omt.tw hdt dah.o  lmdmp g\n",
            "gtaavtnrlnnienhwd\n",
            "LnouvrfEtwmHsenhtb a ;EaMfro\n",
            " da  pealoaaohot hh. sfIsc chlo a eanbrathuoohttdOr\n",
            "usogFinlo WalsS rhsaoidnlo\n",
            "mhonne\n",
            "h a o:elo ny:\n",
            "oA:te'fEo a  n t tuaveOtht\n",
            "m\n",
            "naola od. disihhFh h yh smon-veek\n",
            "teaowbdbtad bu oeiwtb:aey nilohftih o \n",
            "ntn alpdwh AnWae,httl a S ahtaOrNZIsarau  iMohilg, e;o aO;thAllhmAbatuom rr nR.edacdo\n",
            "ww fvlo\n",
            " r.iR;lwlhnaetSoo ih .gportbkIawte Eu  rna:O,irraMa t nr.enrsfnh rirlsufehn\n",
            "Cunlhste wNn : e etnc;w pslnUeraaioLRredvoo hnari eAw\n",
            "wb eo  \n",
            "owaIuwhXimneaao'hoolu A s haunLasAhaa malsyr.hn,o aE   tthcA \n",
            "  rTvTnu tpArr d ou nec uahlAoshddaaeSnat p,\n",
            "lolahyhooIea n iuur nsCPe,r,addnsiu d mdzIhho\n",
            "ie;wgvrt SmISm\n",
            "!di?\n",
            "cd 'CEr  ihalensaasimf fnmns\n",
            "lbne\n",
            "r i ai iriOrIdTr OArnehn i , t caad  r\n",
            "aous'lait hdtS dchKnThuI  hEanunr u\n",
            "uudi? \n",
            "nDn\n",
            "tpa.ahWhle\n",
            "dmNrnn oo\n",
            "Ioauauhutssr nHcc\n",
            " olrTaes\n",
            "'l I nhnsbtymS\n",
            ",   tlutbaohs sainatwuhi dr aqe,lIaIot\n",
            "eImaYvfneo rc\n",
            "car nev,vww \n",
            "neAfA\n",
            ":cthhsen tPme ntIeshaKnea\n",
            "'ua$an   nl oauon.Nn-lOEoGlRosllofB.wo Ir; sn Da 'hrfF\n",
            "te h\n",
            "ae ol.tEI lbmneriu\n",
            "lm,bneectlfa' g avw,nohs\n",
            "sddIhr v\n",
            "\n",
            " svrDsseUr hahwioeuhe r raeKEitl:crhBlaffndns  yShne wWIinnN nalGnd\n",
            "hw   Lldi Eyu'nmanhttsd riwnwrnnId noo\n",
            "b\n",
            "n oAfmchSlnybtrmqcooa,lo lec erfnlfiuaollaOd'rms' \n",
            "  IIru idim,Tniitvt,hshi  whyhwh  saM hceFsncyv.fiopeEo\n",
            "Wn'dhAvIw h, d  ls \n",
            "-thGoOyhm 'W lfaneoeaN,h\n",
            "sh ne thaylier wwadnla,bsfalaanooa\n",
            "ai\n",
            ".aftanDdawaaUahno\n",
            "\n",
            "S\n",
            "t uonId fi  ctllehaya oeAeea ath\n",
            "hlml nlau mnnhn\n",
            "feunhona  oovLeIdboha iyoIhmlehnofr\n",
            "d  n n iel efholnheIrauoinIdhM\n",
            "dou ec trz:assilocthuevredsFlrmwoEawm uwpgdO  UeOhu y ltrd\n",
            "n\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "save_path = 'gpt2_task2.pth'\n",
        "\n",
        "if os.path.isfile(save_path):\n",
        "    model = GPT2SmallWithRotary(vocab_size, n_embd, n_head, n_layer)\n",
        "    model.load_state_dict(torch.load(save_path))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"Model loaded from {save_path}\")\n",
        "    print(sum(p.numel() for p in model.parameters()) / 1e6, 'M parameters')\n",
        "else:\n",
        "    model = GPT2SmallWithRotary(vocab_size, n_embd, n_head, n_layer)\n",
        "    model = model.to(device)\n",
        "    print(sum(p.numel() for p in model.parameters()) / 1e6, 'M parameters')\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for iter in range(max_iters):\n",
        "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "            losses = estimate_loss()\n",
        "            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "        xb, yb = get_batch('train')\n",
        "\n",
        "        logits, loss = model(xb, yb)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"Model saved to {save_path}\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_text = decode(model.generate(context, max_new_tokens=2000)[0].tolist())\n",
        "print(generated_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GroupQueryAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super(GroupQueryAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "\n",
        "        self.key = nn.Linear(embed_dim, embed_dim)\n",
        "        self.value = nn.Linear(embed_dim, embed_dim)\n",
        "        self.query = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size, seq_len, _ = x.size()\n",
        "\n",
        "        k_t = self.key(x).reshape(batch_size, seq_len, self.num_heads, self.head_dim).permute(0, 2, 3, 1)\n",
        "        v = self.value(x).reshape(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        q = self.query(x).reshape(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        attn = torch.matmul(q, k_t) / math.sqrt(q.size(-1))\n",
        "        attn = F.softmax(attn, dim=-1)\n",
        "\n",
        "        y = torch.matmul(attn, v)\n",
        "        y = y.transpose(1, 2)\n",
        "        y = y.reshape(batch_size, seq_len, -1)\n",
        "        return y"
      ],
      "metadata": {
        "id": "YMlT1EzlvIFe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2SmallWithGroupQuery(nn.Module):\n",
        "    def __init__(self,vocab_size=50257, d_model=768, n_heads=12, n_layers=12):\n",
        "        super(GPT2SmallWithGroupQuery, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.n_layers = n_layers\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "        self.rotatory_positional_embedding = RotaryPositionalEmbedding(d_model)\n",
        "        self.transformer_blocks = nn.Sequential(*[TransformerBlock(d_model, n_heads, 512) for _ in range(n_layers)])\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, idx,targets=None):\n",
        "        B, T = idx.shape\n",
        "        x = self.embed(idx)\n",
        "        x = x + self.rotatory_positional_embedding(idx)\n",
        "        x = self.transformer_blocks(x)\n",
        "        logits = self.linear(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, loss = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n"
      ],
      "metadata": {
        "id": "WTws-t1Gxt4P"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "save_path = 'gpt2_task2_group_query.pth'\n",
        "\n",
        "if os.path.isfile(save_path):\n",
        "    model = GPT2SmallWithGroupQuery(vocab_size, n_embd, n_head, n_layer)\n",
        "    model.load_state_dict(torch.load(save_path))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"Model loaded from {save_path}\")\n",
        "    print(sum(p.numel() for p in model.parameters()) / 1e6, 'M parameters')\n",
        "else:\n",
        "    model = GPT2SmallWithGroupQuery(vocab_size, n_embd, n_head, n_layer)\n",
        "    model = model.to(device)\n",
        "    print(sum(p.numel() for p in model.parameters()) / 1e6, 'M parameters')\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for iter in range(max_iters):\n",
        "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "            losses = estimate_loss()\n",
        "            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "        xb, yb = get_batch('train')\n",
        "\n",
        "        logits, loss = model(xb, yb)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"Model saved to {save_path}\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_text = decode(model.generate(context, max_new_tokens=2000)[0].tolist())\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLw85eCMx4zx",
        "outputId": "2b58e7cc-2ef6-48c3-8f73-234a8ea61072"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64.428769 M parameters\n",
            "step 0: train loss 4.4068, val loss 4.4070\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SlidingWindowAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, window_size):\n",
        "        super(SlidingWindowAttention, self).__init__()\n",
        "        self.window_size = window_size\n",
        "        self.conv1d = nn.Conv1d(embed_dim, embed_dim, kernel_size=window_size, stride=1, padding=window_size // 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.conv1d(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        return x"
      ],
      "metadata": {
        "id": "26txLnC5yp5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlockWithSlidingWindowAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads, d_ff):\n",
        "        super(TransformerBlockWithSlidingWindowAttention, self).__init__()\n",
        "        self.self_attention = MultiHeadAttention(d_model, n_heads)\n",
        "        self.feed_forward = FeedForward(d_model, d_ff)\n",
        "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
        "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
        "        self.sliding_attention = SlidingWindowAttention(128, 32)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_output = self.self_attention(x)\n",
        "        x = x + attn_output\n",
        "        sliding_output = self.sliding_attention(x)\n",
        "        x = x + sliding_output\n",
        "        x = self.layer_norm1(x)\n",
        "\n",
        "        ff_output = self.feed_forward(x)\n",
        "        x = x + ff_output\n",
        "        x = self.layer_norm2(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "mkA078XJ2-sa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPT2SmallWithSlidingWindow(nn.Module):\n",
        "    def __init__(self,vocab_size=50257, d_model=768, n_heads=12, n_layers=12):\n",
        "        super(GPT2SmallWithGroupQuery, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.n_layers = n_layers\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.transformer_blocks = nn.Sequential(*[TransformerBlockWithSlidingWindowAttention(d_model, n_heads, 512) for _ in range(n_layers)])\n",
        "        self.linear = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, idx,targets=None):\n",
        "        B, T = idx.shape\n",
        "        x = self.token_embedding_table(idx)\n",
        "        x = x + self.position_embedding_table(torch.arange(T, device=device))\n",
        "        x = self.transformer_blocks(x)\n",
        "        logits = self.linear(x)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B * T, C)\n",
        "            targets = targets.view(B * T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            logits, loss = self(idx_cond)\n",
        "            logits = logits[:, -1, :]\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "        return idx\n"
      ],
      "metadata": {
        "id": "MQBaddID1K3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "save_path = 'gpt2_task2_group_query.pth'\n",
        "\n",
        "if os.path.isfile(save_path):\n",
        "    model = GPT2SmallWithSlidingWindow(vocab_size, n_embd, n_head, n_layer)\n",
        "    model.load_state_dict(torch.load(save_path))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"Model loaded from {save_path}\")\n",
        "    print(sum(p.numel() for p in model.parameters()) / 1e6, 'M parameters')\n",
        "else:\n",
        "    model = GPT2SmallWithSlidingWindow(vocab_size, n_embd, n_head, n_layer)\n",
        "    model = model.to(device)\n",
        "    print(sum(p.numel() for p in model.parameters()) / 1e6, 'M parameters')\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for iter in range(max_iters):\n",
        "        if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "            losses = estimate_loss()\n",
        "            print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "        xb, yb = get_batch('train')\n",
        "\n",
        "        logits, loss = model(xb, yb)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"Model saved to {save_path}\")\n",
        "\n",
        "model.eval()\n",
        "\n",
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_text = decode(model.generate(context, max_new_tokens=2000)[0].tolist())\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "JwYJWDkj3ywv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0rNRgY4938xe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}